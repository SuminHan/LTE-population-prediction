{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11e19e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:59:24.152225: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-21 10:59:24.731274: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:\n",
      "2023-03-21 10:59:24.731298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035d199d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ConvGRU.py',\n",
       " 'CoordConv.py',\n",
       " 'Attention.py',\n",
       " '__pycache__',\n",
       " '__init__.py',\n",
       " 'utils.py']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b97d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.Attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5383b9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'attention_layer_1' (type AttentionLayer).\n\n{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [6,32,32,128] vs. [6,32,32,64] [Op:AddV2]\n\nCall arguments received by layer 'attention_layer_1' (type AttentionLayer):\n  • x=tf.Tensor(shape=(6, 32, 32, 64), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m attention_layer \u001b[38;5;241m=\u001b[39m AttentionLayer(input_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, output_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Call AttentionLayer on input tensor\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m output_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mattention_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrand_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Create a Keras model with the AttentionLayer as a layer\u001b[39;00m\n\u001b[1;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39minput_tensor, outputs\u001b[38;5;241m=\u001b[39moutput_tensor)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/disk1/jupyter/smhan/building-road-data-construction/experiment/mymodels/mydgmr/layers/Attention.py:77\u001b[0m, in \u001b[0;36mAttentionLayer.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     75\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_conv(out)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Residual connection.\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'attention_layer_1' (type AttentionLayer).\n\n{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [6,32,32,128] vs. [6,32,32,64] [Op:AddV2]\n\nCall arguments received by layer 'attention_layer_1' (type AttentionLayer):\n  • x=tf.Tensor(shape=(6, 32, 32, 64), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# Define input tensor\n",
    "# input_tensor = tf.keras.layers.Input(shape=(32, 32, 64))\n",
    "import numpy as np\n",
    "\n",
    "rand_tensor = np.random.rand(6, 32, 32, 64)\n",
    "\n",
    "\n",
    "# Create AttentionLayer instance\n",
    "attention_layer = AttentionLayer(input_channels=64, output_channels=128)\n",
    "\n",
    "# Call AttentionLayer on input tensor\n",
    "output_tensor = attention_layer(rand_tensor)\n",
    "\n",
    "# Create a Keras model with the AttentionLayer as a layer\n",
    "model = tf.keras.models.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "# Print model summary to see input and output shapes\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105cc65e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
